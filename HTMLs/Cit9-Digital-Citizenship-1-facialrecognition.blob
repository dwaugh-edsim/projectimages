{
  "metadata": {
    "id": "DP-ACT-001",
    "title": "The Digital Privacy Act",
    "description": "A high-stakes legislative simulation where students act as members of the Standing Committee on Justice to draft amendments for Facial Recognition Technology in Canada.",
    "author": "Situation Room Archives",
    "version": "1.0",
    "learningOutcomes": [
      "Learners will evaluate risks, rights, and responsibilities of digital citizens.",
      "Learners will analyse how issues become valued within and across all areas of government and society.",
      "Learners will evaluate the consequences of action and inaction as twenty-first century global citizens.",
      "Learners will investigate the structure, operation, and selection of government in Canada."
    ]
  },
  "theme": {
    "layout": "immersive",
    "accent": "#00d2ff",
    "fontH": "Courier New, monospace",
    "fontP": "Georgia, serif",
    "splashHeroURL": "https://images.unsplash.com/photo-1550751827-4bd374c3f58b?q=80&w=2070&auto=format&fit=crop"
  },
  "intelligenceGlossary": [
    {
      "term": "Facial Recognition Technology (FRT)",
      "definition": "Biometric software capable of identifying an individual by comparing facial features against a database."
    },
    {
      "term": "Section 8 (Charter)",
      "definition": "The Charter right protecting citizens against 'unreasonable search or seizure' by the state."
    },
    {
      "term": "The Oakes Test",
      "definition": "A legal test used by courts to determine if a violation of a Charter right is justifiable in a free and democratic society."
    },
    {
      "term": "Judicial Review",
      "definition": "The power of the courts to ensure that government laws and actions comply with the Constitution."
    },
    {
      "term": "Amendment",
      "definition": "A formal change or addition proposed to a bill during the committee stage."
    },
    {
      "term": "Biometric Data",
      "definition": "Unique biological measurements, such as facial geometry or fingerprints, used for identification."
    }
  ],
  "reflections": {
    "pre": [],
    "pre_narrative": "## Committee Session 01\n\nThe Committee Room is silent. On the table before you lies the proposed **Digital Privacy Act**. This legislation proposes the deployment of advanced Facial Recognition Technology in public spaces across the province to combat rising crime rates. Law enforcement claims this is essential for safety. Civil liberties groups claim it is a violation of the Charter of Rights and Freedoms.\n\nYou have been summoned as a member of the **Standing Committee on Justice**. You must draft the 'Rules for Usage'—the protocols that will determine how this technology is used, who is watched, and what data is kept. The Minister is waiting for your amendments. The cameras are waiting to be turned on. The nation is watching.",
    "post": [
      "The Charter of Rights and Freedoms protects against 'unreasonable search and seizure.' Does the constant scanning of faces in public constitute an unreasonable search, even if no crime has been committed?",
      "If a technology has a 1% error rate and is applied to a city of 1 million people, thousands could be falsely flagged. Is this an acceptable margin of error for a democratic society?",
      "Compare Canada's approach to this technology with an authoritarian model. What specific clause in your bill prevents the state from sliding toward total surveillance?"
    ],
    "post_narrative": "## Session Adjourned\n\nThe amendments have been filed. The bill now moves to the House for a final vote. The protocols you drafted will define the boundary between security and liberty for the next generation. History will judge whether you protected the safety of the public or the freedom of the individual."
  },
  "slides": [
    {
      "id": "slide_1",
      "shortTitle": "A-1: The Bill",
      "longTitle": "Exhibit A-1: The Legislative Proposal",
      "tabs": {
        "primary": {
          "body": "The Digital Privacy Act\n-----------------------\n\nThe proposal on the table is the **Digital Privacy Act**, a piece of legislation that aims to modernize how public safety is maintained in the 21st century. The core technology involved is **Facial Recognition Technology (FRT)**. This system uses algorithms to map facial features from video feeds and compare them against criminal databases in real-time.\n\nWhy It Is Being Proposed\n------------------------\n\nLaw enforcement agencies argue that the modern world has become too complex for traditional policing. They claim they need advanced tools to prevent terrorist attacks, locate missing persons quickly, and identify violent offenders in crowded spaces. They argue that speed is synonymous with safety.\n\nThe Legislative Process Begins\n------------------------------\n\nAs members of a parliamentary committee, your journey begins with the **First Reading**. This is a formality where the bill is introduced. The critical phase is the **Committee Stage**, where you are now. Here, you can propose **Amendments**. You have the power to change the text of the bill. You might decide that the police should only use this technology in specific situations, or you might demand strict oversight.\n\nThe Risk of Inaction\n--------------------\n\nIf the committee does not act, the **Privacy Act** in Canada (specifically the Canadian Charter of Rights and Freedoms, Section 8) could be violated. Section 8 protects against 'unreasonable search and seizure.' If the government watches everyone, everywhere, without a reason, that is a violation of privacy. Your task is not to decide _if_ the police get the technology, but _how_ they are allowed to use it.",
          "image": "https://images.unsplash.com/photo-1555431189-0fabf2667795?q=80&w=1928&auto=format&fit=crop",
          "credit": "ARCHIVE: Legislative Text"
        },
        "legal": {
          "body": "Anatomy of a Committee\n----------------------\n\nYou are sitting in a room with wood-paneled walls. There are two long tables arranged in a U-shape. At the center, facing the committee members, is a witness table. This is where the work of democracy happens.\n\nWho is in the Room?\n-------------------\n\nThe Structure of Debate\n-----------------------\n\nDebate in committee is structured. You have a limited time for **Opening Statements** and a **Round of Questions**. This is where you use **Question Period** tactics to uncover the truth. For example: 'What is your error rate? Will this technology misidentify people of color more often?'\n\nDrafting Amendments\n-------------------\n\nThe committee members have the power to propose **Subamendments**. If the bill says 'Police may use FRT in all public places,' you can propose an amendment to change 'all public places' to 'only designated high-security zones.' This requires precise language.\n\nThe Voting Process\n------------------\n\nAfter hearing from witnesses, the committee votes clause-by-clause. If a clause is voted down, it is removed. Your goal is to produce a bill that the House can actually pass, and that the Senate will not reject.",
          "image": "https://images.unsplash.com/photo-1575505586569-646b2ca898fc?q=80&w=2070&auto=format&fit=crop",
          "credit": "ARCHIVE: Committee Chamber"
        },
        "intel": {
          "body": "The Core Conflict: Safety vs. Liberty\n-------------------------------------\n\nThe debate is between **Collective Security** and **Individual Liberty**.\n\nThe Argument for Security\n-------------------------\n\nProponents argue privacy is not absolute. They use the 'Nothing to Hide' argument: 'If you are not doing anything wrong, you have nothing to fear.' They claim the efficiency of FRT saves taxpayer money and lives by catching criminals faster than human officers ever could.\n\nThe Argument for Liberty\n------------------------\n\nOpponents argue that constant monitoring creates a **'Chilling Effect.'** If people know they are being watched, they might be afraid to go to political protests or meet with whistleblowers. They also point to the **'Slippery Slope'**: allowing FRT today for serious crimes might lead to tracking parking violations or political dissent tomorrow.\n\nThe 'Rules for Usage' Concept\n-----------------------------\n\nYou need **'Rules for Usage'** (similar to military Rules of Engagement). These define:\n\n  \n\nParliamentary Tactics\n---------------------\n\nIf the bill is bad, you might use debate to **Filibuster** (delay) to force negotiation. However, the government usually has the majority. Your debate is the only tool to force compromise.",
          "image": "https://images.unsplash.com/photo-1529070538774-1843cb3265df?q=80&w=2070&auto=format&fit=crop",
          "credit": "ARCHIVE: Strategic Overview"
        }
      },
      "interactionPrompt": "The Minister has tabled the initial draft. Do you move to debate the 'Scope of Usage' clause immediately, or call expert witnesses on privacy rights first?",
      "options": [
        "DEBATE SCOPE",
        "CALL WITNESSES"
      ]
    },
    {
      "id": "slide_2",
      "shortTitle": "B-1: Legal Rights",
      "longTitle": "Exhibit B-1: The Charter Shield",
      "tabs": {
        "primary": {
          "body": "Section 8: Search and Seizure\n-----------------------------\n\nThe supreme law is the **Constitution Act, 1982**, containing the **Canadian Charter of Rights and Freedoms**. **Section 8** is your shield.\n\n**Section 8 states:** _'Everyone has the right to be secure against unreasonable search or seizure.'_\n\nWhat is 'Unreasonable'?\n-----------------------\n\nThe Supreme Court has ruled that a search is 'reasonable' only if:\n\n  \n\nThe Identity Search\n-------------------\n\nDoes FRT constitute a 'search'? Your face is public. But if a computer instantly cross-references it with your private life and tracks your movements over time, does that violate your expectation of privacy? This is the central legal question you must answer in your drafting.",
          "image": "https://images.unsplash.com/photo-1589829085413-56de8ae18c73?q=80&w=2012&auto=format&fit=crop",
          "credit": "ARCHIVE: Legal Texts"
        },
        "legal": {
          "body": "The 'Usage Protocols'\n---------------------\n\nYou must write **Biometric Usage Protocols (BUP)** into the bill.\n\nProtocol 1: The Trigger\n-----------------------\n\nAvoid **Continuous Mass Surveillance**. Draft a rule that allows FRT only for an 'imminent threat' or with a 'specific warrant.'\n\nProtocol 2: Data Retention\n--------------------------\n\nDraft the 'Kill Switch.' If a scan does not match a criminal record, the data must be deleted immediately. Prevents the government from building a database of innocent people.\n\nProtocol 3: Error Rates and Bias\n--------------------------------\n\nFacial recognition struggles with women and people of color. Draft a clause: 'Software must have an error rate below 1% for all demographic groups before deployment.'\n\nProtocol 4: Transparency\n------------------------\n\nDraft a clause requiring the police to publish a quarterly report: How many scans? How many errors? How many arrests?\n\nProtocol 5: Judicial Oversight\n------------------------------\n\nDraft a clause: 'Any data obtained via FRT without a warrant is inadmissible in court.' This is the 'Fruit of the Poisonous Tree' doctrine.",
          "image": "https://images.unsplash.com/photo-1450101499163-c8848c66ca85?q=80&w=2070&auto=format&fit=crop",
          "credit": "ARCHIVE: Drafting Amendments"
        },
        "intel": {
          "body": "## The Courts as the Final Arbiter\nEven if you pass the law, the **Courts** can strike it down via **Judicial Review**.\n\n## The Charter Challenge\nIf civil liberties groups believe your rules are weak, they will sue. They will claim the law violates Section 8. The judge does not care about 'public safety' arguments if the law violates rights.\n\n## The 'Court-Proof' Law\nYour goal is to write a law that respects Section 8 so perfectly that no judge can strike it down. Look at **R. v. Spencer**: The Supreme Court ruled that internet users have a privacy interest in their IP addresses. This established that **anonymity is a form of privacy**.\n\nIf the law allows police to scan citizens without a reason, it will likely be struck down. You must limit the use to maintain privacy expectations.",
          "image": "https://images.unsplash.com/photo-1563205764-6e927cdbcb65?q=80&w=1974&auto=format&fit=crop",
          "credit": "ARCHIVE: Supreme Court"
        }
      },
      "interactionPrompt": "Privacy groups are demanding a 'Warrant Requirement' for all scans. Police warn this will slow response times. How do you amend the Authorization Clause?",
      "options": [
        "REQUIRE WARRANT",
        "ALLOW DISCRETION"
      ]
    },
    {
      "id": "slide_3",
      "shortTitle": "C-1: Intel Brief",
      "longTitle": "Exhibit C-1: Global & Technical Analysis",
      "tabs": {
        "primary": {
          "body": "How FRT Works\n-------------\n\n  \n\nThe 'Black Box' Problem\n-----------------------\n\nMany algorithms are proprietary. The police might not know how the 'decision' is made. This is a problem for accountability. If you cannot explain the tech, you cannot prove it worked in court.\n\nFalse Positives\n---------------\n\nA **False Positive** is an innocent person identified as a criminal. The consequence is humiliation, wrongful arrest, and public fear. This creates mistrust between police and community.",
          "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?q=80&w=2070&auto=format&fit=crop",
          "credit": "ARCHIVE: Biometric Scan"
        },
        "legal": {
          "body": "China: The Authoritarian Model\n------------------------------\n\nTotal integration, no opt-out, no privacy laws. Used for mass control and social scoring. **Outcome:** Zero dissent, human rights violations.\n\nUSA: The Patchwork Model\n------------------------\n\nNo federal privacy law. Many cities (SF, Boston) have banned police use due to bias. High litigation. **Outcome:** Unstable, varies by location.\n\nEurope: The GDPR Model\n----------------------\n\nTreats biometric data as 'special category.' Requires strict consent and purpose. Puts burden of proof on the government. **Outcome:** High privacy, slower tech adoption.\n\nRecommendation\n--------------\n\nLook to the **European** model for strict regulation, but adapt for police use (where consent is impossible). We need a uniquely Canadian solution that prohibits mass surveillance but allows targeted, warrant-based use.",
          "image": "https://images.unsplash.com/photo-1529400971008-f566de0e6dfc?q=80&w=2070&auto=format&fit=crop",
          "credit": "ARCHIVE: Global Map"
        },
        "intel": {
          "body": "The Citizen's Voice\n-------------------\n\nYou are accountable to voters.\n\nThe Stakeholders\n----------------\n\n  \n\nManaging the Narrative\n----------------------\n\nThe Government frames it as **'Safety vs. Criminals.'** You must reframe it as **'Freedom vs. Control.'**\n\nThe 'Chilling Effect'\n---------------------\n\nIf the public sees mass surveillance, they self-censor. They stop attending protests. They stop searching for controversial topics. A government that surveils its people is preparing for civil unrest.\n\nYour committee must use public pressure. If the public opposes the bill, you can force the government to withdraw it or add strict amendments.",
          "image": "https://images.unsplash.com/photo-1531206715517-5c0ba140b2b8?q=80&w=2070&auto=format&fit=crop",
          "credit": "ARCHIVE: Public Protest"
        }
      },
      "interactionPrompt": "A 'False Positive' scandal has just hit the news. Do you propose a pause on the bill to investigate, or push forward with strict error-rate limits?",
      "options": [
        "PAUSE BILL",
        "PUSH FORWARD"
      ]
    },
    {
      "id": "slide_4",
      "shortTitle": "D-1: Operations",
      "longTitle": "Exhibit D-1: The Operational Reality",
      "tabs": {
        "primary": {
          "body": "## The Police Perspective\nTo write fair rules, understand the operational reality.\n\n## The 'Lead Time' Problem\nIn a kidnapping case, the first 24 hours are critical. Police want 'Real-Time' access to scan live feeds.\n\n## The Risk of Over-Reliance\nIf a computer says 'Suspect,' officers might stop thinking critically (Automation Bias). They might ignore their intuition.\n\n## The Budget\nHigh-tech surveillance is expensive. Who pays? The City? The Feds? This takes money away from community policing (officers walking the beat).\n\n## The 'Trusted Partner' Dynamic\nPolice solve crimes because the community helps them. If the community hates the cameras, they stop talking to the police. Cooperation drops.",
          "image": "https://images.unsplash.com/photo-1461988625982-7e46a0540bfc?q=80&w=2069&auto=format&fit=crop",
          "credit": "ARCHIVE: Law Enforcement"
        },
        "legal": {
          "body": "## The City Council Level\nWhile the Act is federal, cameras are installed in cities. Cities have **Bylaws**.\n\n## Jurisdiction\nWho owns the street? The City. Who wants cameras? The Police.\n\n## The Leverage\nCities can pass bylaws banning surveillance technology. If the City Council refuses to install cameras on light poles, the federal plan fails.\n\n## Community Consultation\nCity councils hold town halls. Residents can say: 'I don't want cameras recording my kids in the park.'\n\n## 'Privacy Sanctuaries'\nSome cities declare themselves 'Privacy Sanctuaries.' They refuse to cooperate with federal surveillance. Your bill must address this municipal friction.",
          "image": "https://images.unsplash.com/photo-1480714378408-67cf0d13bc1b?q=80&w=2070&auto=format&fit=crop",
          "credit": "ARCHIVE: Urban Council"
        },
        "intel": {
          "body": "## The Flow of Power\n1. **House of Commons:** You debate and vote.\n2. **Senate:** They check legality (Royal Assent).\n3. **Law:** It exists.\n4. **Implementation:** Police create internal policies.\n5. **Enforcement:** Privacy Commissioner audits.\n\n## The 'Bureaucratic Drag'\nBureaucrats can slow implementation if they disagree. You must write strict timelines into the bill (e.g., 'Comes into force 90 days after Royal Assent').\n\n## The Goal\nYour amendments act as the 'trigger' for the rest of the system. If you write weak rules, the system produces weak privacy protection.",
          "image": "https://images.unsplash.com/photo-1541872703-74c5963631df?q=80&w=2070&auto=format&fit=crop",
          "credit": "ARCHIVE: Government Building"
        }
      },
      "interactionPrompt": "Municipalities are threatening to block camera installation. Do you override their bylaws with federal power, or mandate local approval?",
      "options": [
        "FEDERAL OVERRIDE",
        "LOCAL MANDATE"
      ]
    },
    {
      "id": "slide_5",
      "shortTitle": "E-1: Compliance",
      "longTitle": "Exhibit E-1: Oversight & Compliance",
      "tabs": {
        "primary": {
          "body": "## The Privacy Commissioner\nThe Office of the Privacy Commissioner (OPC) is the watchdog. They investigate complaints.\n\n## Current Powers\nThey can audit and investigate, but currently, they lack **Order-Making Power**. They can only recommend changes.\n\n## Your Legislative Power\nYou can draft a clause giving the Commissioner **Order-Making Power**.\n*Example:* 'The Commissioner may order the police to stop using the technology if they violate the rules.'\n\n## Enforcement vs. Cooperation\nThe police will argue that the Commissioner slows them down. You must decide: Is speed more important than rights? Enforcement is necessary for the law to have teeth.",
          "image": "https://images.unsplash.com/photo-1599256621730-d3169f18131c?q=80&w=2070&auto=format&fit=crop",
          "credit": "ARCHIVE: Oversight Office"
        },
        "legal": {
          "body": "## The 'Hansard'\nYour notebook contains the **Hansard** (official record). Courts use Hansard to understand the 'Intent' of the law.\n\n## Key Phrases to Draft\nYour notebook should contain:\n* *“Reasonable Expectation of Privacy”*\n* *“Proportional Use”*\n* *“Judicial Oversight”*\n* *“Independent Audit”*\n\n## The 'Poison Pill'\nIf the bill is fundamentally bad, you can add a 'Poison Pill' clause to kill it. Example: 'The Minister of Public Safety must personally approve every single scan.' This makes the law impossible to implement, forcing the government to withdraw it.",
          "image": "https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?q=80&w=2070&auto=format&fit=crop",
          "credit": "ARCHIVE: Legal Drafts"
        },
        "intel": {
          "body": "## Technical Safeguards\nYou cannot just say 'keep data safe.' You must mandate how.\n\n## Encryption\nData must be encrypted 'at rest' (on servers) and 'in transit' (over the network).\n\n## Access Control\n**Principle of Least Privilege:** Only the specific officer investigating a specific case should have access.\n\n## Audit Logs\nThe system must record every time someone accesses data. If an officer looks up their ex-partner, there must be a digital trail.\n\n## Ransomware Risk\nPolice databases are targets for hackers. A leak of surveillance data is a national security risk. The law must mandate high-security standards.",
          "image": "https://images.unsplash.com/photo-1558494949-efc025793ad0?q=80&w=2069&auto=format&fit=crop",
          "credit": "ARCHIVE: Server Encryption"
        }
      },
      "interactionPrompt": "The police demand independent audits be kept secret for 'security reasons.' Do you agree to secrecy, or demand public transparency?",
      "options": [
        "SECRET AUDITS",
        "PUBLIC TRANSPARENCY"
      ]
    },
    {
      "id": "slide_6",
      "shortTitle": "F-1: Strategy",
      "longTitle": "Exhibit F-1: Strategic & Global Impact",
      "tabs": {
        "primary": {
          "body": "## The Political Reality\nTechnically, you can write a perfect law. Politically, you need votes.\n\n## The Polling Data\nLet's say:\n* **45%** Support (Safety)\n* **40%** Oppose (Privacy)\n* **15%** Undecided\n\n## The 'Safe' Compromise\nUndecided voters break towards safety if scared, privacy if watched.\n*Strategy:* Draft a bill that **looks** tough on crime but has **strict** privacy limits. Brand it: 'The Safe Streets and Privacy Protection Act.'\n\n## The Lobbyists\nThe **Tech Industry** wants to sell software. The **Civil Liberties Groups** want to protect rights. You must weigh the money against the votes.",
          "image": "https://images.unsplash.com/photo-1460925895917-afdab827c52f?q=80&w=2015&auto=format&fit=crop",
          "credit": "ARCHIVE: Polling Data"
        },
        "legal": {
          "body": "## The Backend Hardware\n\n## The Network\nCameras need 5G or fiber. If the network is jammed, the system fails.\n\n## The Server Farm\nWhere is data stored?\n* **Cloud:** Flexible, potentially less secure.\n* **On-Premise:** Secure, expensive.\n\n## Jurisdiction\nThe law must mandate: **Data stays in Canada.** If a US company hosts the data, the US government (via CLOUD Act) could demand access. That is a foreign jurisdiction issue.",
          "image": "https://images.unsplash.com/photo-1544197150-b99a580bbc7f?q=80&w=2069&auto=format&fit=crop",
          "credit": "ARCHIVE: Infrastructure"
        },
        "intel": {
          "body": "## The Canadian Flag\n\n## What Does Canada Stand For?\nCanada is known as a 'Middle Power' and a 'Peacekeeper' with the **Charter of Rights**. We are *not* known for mass surveillance.\n\n## The Choice\n* **No Rules:** We slide towards an authoritarian state.\n* **Strict Rules:** We become a global leader in **Ethical AI**.\n\n## Your Legacy\nFuture generations will look back. Will they see a government that panicked and sacrificed freedom? Or a government that protected democracy?\n\nThe 'Rules for Usage' you draft today determine that future.",
          "image": "https://images.unsplash.com/photo-1535359708915-2efc2770289a?q=80&w=2070&auto=format&fit=crop",
          "credit": "ARCHIVE: National Symbol"
        }
      },
      "interactionPrompt": "Final Decision: Do you vote to PASS the bill with your amendments, or REJECT it entirely as too dangerous?",
      "options": [
        "PASS WITH AMENDMENTS",
        "REJECT ENTIRELY"
      ],
      "historicalOutcome": "## The Committee's Decision\n\nIf you voted to **Pass with Amendments**, you have established a regulated framework. Canada likely becomes a model for 'Ethical AI,' limiting police power while allowing for modernization.\n\nIf you voted to **Reject Entirely**, you have stopped the immediate deployment, but the pressure will return. Police may attempt to use the technology covertly or without regulation until a new law is forced upon them."
    }
  ],
  "epilogue": {
    "whatIf": [
      {
        "scenario": "What if you allowed mass surveillance?",
        "outcome": "Crime rates might drop by 5-10% in the short term, but trust in government would plummet. Protest movements would likely be suppressed, leading to long-term civil unrest."
      },
      {
        "scenario": "What if you banned FRT entirely?",
        "outcome": "Privacy would be absolute, but police would be slower to solve major crimes. In the event of a terrorist attack, the public might blame the government for 'tying the hands' of the police."
      }
    ],
    "staticDebrief": "The balance between security and liberty is the central tension of democracy. In this simulation, you engaged with the legislative process to define that balance. Review your decisions: Did you prioritize the efficiency of the state or the rights of the individual?"
  }
}